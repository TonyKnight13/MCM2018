### 4.1 Data Screening

The amount of data is large, so the first thing is to filter the data based on its completeness
and validity.

First, we screen the data of 30,000 historical business data provided by the lender:

- Since tag attributes are crucial and can not be completed, we delete all business data that did not indicate a value.
- In the analysis of the attributes, we find that there are a large number of missing
attributes of AGENT and salary levels in the data, in which the salary levels can be complemented because it is a numerical attribute with continuous meaning. For AGENT, because it is text type data and we did not find it related to other attributes,so we choose to delete AGENT this attribute.
- The proportion of default and non-default data is unbalanced. Considering that many training models require sample balance, certain strategies need to be adopted to balance the data. We find the data's ratio is about 1:25, so we use both the undersampling and oversampling at the same time.

### 4.2 Data merging

- In data processing, we find that there are four values repeated for the education level variables. The variable has repeated values which contain junior college degree and blow, junior college degree, senior high school degree and junior high school degree. Also there are repeated values which are graduate, doctoral and master’s degree and more than three kinds of classification. So, we combine the former into one class and the latter into the other.
- At the same time, we find that two kinds of definitions of divorce and divorced were duplicated in the marital status. We merged them into the divorce. Beyond that, we considered the semantic description of marital status. We merged the widowhood into the divorce and merged the other circumstances into the unmarried.
- For the borrowing time, the data provided to us is only from January to June in 2017, so we make the date according to the month, so as to facilitate the later use.
- For ID information, because of it providing the working province and local cadastral data, so We can extract information about the birthplace from these two attributes. And according to the hypothesis, birthplace has no effect on the prediction, so we only retain the information about gender in the identity card.
- We according to the 16th national congress of the communist party of China to the division of economic regions across the country, refer to the provinces economic development last year, the provinces will be divided into eastern, northeast, central and western four large range, as shown Figure 1.

<!-- 图1 -->

### 4.3 Missing Value Processing

In statistics, missing data occur when no data value is stored for the variable in an observation.Missing data are a common occurrence and can have a significant effect on the conclusions that can be drawn from the data.

In the data, There is a large amount of data missing salary level this one variable, because of a lack of large amount of data and the variable is a numerical data with order, so we consider it to complete it. We make statistics on the unmissing data and find that the total data is in a normal distribution.

Then we consider the salary level may be affected by education level and work area, so we assume that people of different education level and work areas salary level, and to analyze it.

<!-- 图2 -->


<!-- 图3 -->


<!-- 图4 -->

We find that at different education level, the salary level is basically in normal distribution. In master's or higher education level, the proportion of high salary level compared with other education level is higher, but considering the data to the education level in according to the proportion of the total amount is so low, in order to facilitate processing, we also consider it a normal distribution. So we're going to take a bunch of different education levels to fill in.

For different work areas, we also analyze their salary level respectively.

<!-- 图 -->


<!-- 图 -->


<!-- 图 -->


<!-- 图 -->

We also found that in different working areas, all salary levels were in a normal distribution, so we concluded that the salary level in the data presented a normal distribution, which was not affected by education level and the working area.

For this, we calculated their average and mode and plotted the correlation chart for preliminary analysis. We can see that the average is 3.58, the mode is 3. Considering the various aspects and convenience of our later use, we decided to set the missing value of all salary level to 3.

<!-- 表1 -->

### 4.4 Unbalanced data processing

According to the statistics of the data label quantity, the number of non-defaults is far greater than the number of defaults, which makes our model predict all the results in training without default, and the final accuracy is as high as 0.9 on the surface, but the actual prediction accuracy of default is closed to zero. To avoid this phenomenon, we have conducted undersampling and over-sampling processing of the data, and reduce the sample gap between the two types of customers. We've tried multiple sampling and undersampling. The overall strategy is that the data owed to customers without default should be kept as many original samples as possible, and the data of the defaulting customer should not be far more than the original sample.

# 6 Analysis of the Result

### 6.1 Problem 1

After the chi-square test of each attribute and the default, we were surprised to find that the gender, marital status and the ownership of the fund had no significant relationship with the result, which means that the weight of these three variables was almost 0.
In order to know which other data in the remaining variables influence on whether the default is large, we need to analyze the weight of each variable, by analyzing the results, we found that the most important factor is the salary level, that is to say, salary is the most important factor in our credit evaluation system. The remaining variables are ranked in order of the importance of the credit rating system:

- salary level
- working province
- education level
- is local
- borrowing time

### 6.2 Problem 3

As shown in the table, the accuracy rate of the test data is 0.74, the recall rate is 0.51, and the overall prediction accuracy is 0.62, which is not good overall. However, for the prediction of credit assessment, the recall rate is more important, so the recall rate of 0.51 also basically meets the demand.

<!-- 表  结果分析 -->




### 7.3 Improvement

- using a single logistic regression model is not effective, follow-up can use adaboost and other integrated learning will be a number of simple model collection
- The use of a single logistic regression model is not very effective, and some integration learning methods can be used to train later.

Logistic regression has a strong dependence on data on this issue, so we consider using decision tree for training.

The common advantages of decision tree algorithm are as follows:

- high classification accuracy;
- the generated model is simple;
- good robustness against noise data.

We chose the gini coefficient as the basis for partition, the gini index (gini) : the probability that a randomly selected sample in the sample collection was misclassified.

The overall data as before, adjusted the following test.

Information entropy:

<!-- 信息熵公式 -->

Gini Coefficient:

<!-- 基尼系数 -->

Calculation can be a variety of evaluation indicators are as follows:

- accuary 0.691375
- recall 0.669119512814
- precision 0.693582325092

It can be seen that the decision tree performance is better overall compared with the previous logistic regression. At this point, the adverse impact of the relatively small sample size of the default client is greatly reduced. There is no tendency to predict the situation of non-defaulting clients. So, it seems, sampling and undersampling in the role of the decision tree is more obvious. The common credit evaluation index obtained from the Internet shows that 60% is acceptable and 70% is good.